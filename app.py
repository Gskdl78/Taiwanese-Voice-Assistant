#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°èªèªéŸ³å°è©± Web æ‡‰ç”¨ç¨‹å¼
æ•´åˆå°èª STT + æ„å‚³ç§‘æŠ€ APIï¼ˆæ¨™éŸ³ + TTSï¼‰+ LLM å°è©±
åŸºæ–¼ TauPhahJi-BangTsam å°ˆæ¡ˆçš„ API è¦ç¯„
"""

import os
import time
import tempfile
import subprocess
import re
from flask import Flask, render_template, request, jsonify, send_file
import librosa
import soundfile as sf
import numpy as np
import torch
import torchaudio
import torchaudio.transforms as T
from transformers import WhisperProcessor, WhisperForConditionalGeneration, pipeline
import requests
from urllib.parse import urlencode, quote

# åŒ¯å…¥æ–°çš„TTSæœå‹™å’Œæ ¼å¼è½‰æ›å™¨
from remote_tts_service import RemoteTtsService
from romanization_converter import RomanizationConverter

# åŒ¯å…¥æ€§èƒ½é…ç½®
try:
    from performance_config import (
        get_current_config, get_optimization_suggestions,
        apply_performance_mode, PERFORMANCE_MODE
    )
    PERFORMANCE_CONFIG_AVAILABLE = True
except ImportError:
    print("âš ï¸ æ€§èƒ½é…ç½®æ¨¡çµ„æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é è¨­é…ç½®")
    PERFORMANCE_CONFIG_AVAILABLE = False
    PERFORMANCE_MODE = "fast"

app = Flask(__name__)

# å…¨åŸŸè®Šæ•¸
CLEANUP_FILES = True  # æ˜¯å¦æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
AUDIO_SAMPLE_RATE = 16000  # éŸ³è¨Šå–æ¨£ç‡
MAX_AUDIO_DURATION = 30  # æœ€é•·éŸ³è¨Šæ™‚é–“ï¼ˆç§’ï¼‰
MIN_AUDIO_DURATION = 0.5  # æœ€çŸ­éŸ³è¨Šæ™‚é–“ï¼ˆç§’ï¼‰

def debug_print(message):
    """èª¿è©¦è¼¸å‡ºå‡½æ•¸"""
    print(f"[DEBUG] {message}")

def performance_timer(func_name):
    """æ€§èƒ½è¨ˆæ™‚è£é£¾å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            print(f"â±ï¸  é–‹å§‹åŸ·è¡Œ: {func_name}")
            
            try:
                result = func(*args, **kwargs)
                end_time = time.time()
                duration = end_time - start_time
                print(f"âœ… {func_name} å®Œæˆ - è€—æ™‚: {duration:.3f}ç§’")
                return result
            except Exception as e:
                end_time = time.time()
                duration = end_time - start_time
                print(f"âŒ {func_name} å¤±æ•— - è€—æ™‚: {duration:.3f}ç§’ - éŒ¯èª¤: {e}")
                raise
                
        return wrapper
    return decorator

def log_step_time(step_name, duration, details=""):
    """è¨˜éŒ„æ­¥é©ŸåŸ·è¡Œæ™‚é–“"""
    print(f"ğŸ“Š ã€{step_name}ã€‘è€—æ™‚: {duration:.3f}ç§’ {details}")

# å…¨åŸŸè®Šæ•¸
taiwanese_processor = None
taiwanese_model = None
device = None
ffmpeg_path = None
pipeline_asr = None
remote_tts_service = None
romanization_converter = None

# éŸ³è¨Šé è™•ç†åƒæ•¸
AUDIO_PREPROCESSING = {
    "remove_silence": True,  # ç§»é™¤éœéŸ³
    "noise_reduction": True,  # é™å™ª
    "normalize_volume": True,  # éŸ³é‡æ­£è¦åŒ–
    "silence_threshold": 0.05,  # éœéŸ³é–¾å€¼
    "min_silence_duration": 0.3,  # æœ€å°éœéŸ³æ™‚é–“ï¼ˆç§’ï¼‰
}

def preprocess_audio(audio_path):
    """
    éŸ³è¨Šé è™•ç†å‡½æ•¸ï¼ˆä½¿ç”¨ GPU åŠ é€Ÿï¼‰
    
    Args:
        audio_path (str): è¼¸å…¥éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
        
    Returns:
        str: è™•ç†å¾Œçš„éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
    """
    try:
        print(f"ğŸµ é–‹å§‹éŸ³è¨Šé è™•ç†: {audio_path}")
        
        # ä½¿ç”¨ torchaudio è®€å–éŸ³è¨Šï¼ˆæ”¯æ´ GPU åŠ é€Ÿï¼‰
        waveform, sample_rate = torchaudio.load(audio_path)
        
        # ç¢ºä¿å–®è²é“
        if waveform.size(0) > 1:
            waveform = torch.mean(waveform, dim=0, keepdim=True)
        
        # é‡æ¡æ¨£åˆ°ç›®æ¨™æ¡æ¨£ç‡
        if sample_rate != AUDIO_SAMPLE_RATE:
            resampler = T.Resample(sample_rate, AUDIO_SAMPLE_RATE)
            waveform = resampler(waveform)
        
        # ç§»å‹•åˆ° GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
        waveform = waveform.to(device)
        
        if AUDIO_PREPROCESSING["remove_silence"]:
            # ä½¿ç”¨ torchaudio çš„éœéŸ³æª¢æ¸¬
            db_threshold = 20
            frame_length = 2048
            hop_length = 512
            
            # è¨ˆç®—èƒ½é‡
            energy = torch.norm(waveform.view(-1, frame_length), dim=1)
            energy_db = 20 * torch.log10(energy + 1e-10)
            
            # æ‰¾å‡ºééœéŸ³æ®µè½
            mask = energy_db > -db_threshold
            mask = mask.to(device)
            
            # æ‡‰ç”¨é®ç½©
            waveform = waveform.squeeze()
            non_silent = waveform[mask]
            waveform = non_silent.unsqueeze(0)
        
        if AUDIO_PREPROCESSING["noise_reduction"]:
            # ä½¿ç”¨ GPU åŠ é€Ÿçš„é »è­œè™•ç†
            n_fft = 2048
            hop_length = 512
            
            # è¨ˆç®— STFT
            spec = torch.stft(
                waveform.squeeze(),
                n_fft=n_fft,
                hop_length=hop_length,
                window=torch.hann_window(n_fft).to(device),
                return_complex=True
            )
            
            # è¨ˆç®—é »è­œå¹…åº¦
            spec_mag = torch.abs(spec)
            
            # ä¼°è¨ˆå™ªéŸ³é »è­œ
            noise_estimate = torch.mean(spec_mag[:, :10], dim=1, keepdim=True)
            
            # é »è­œæ¸›æ³•
            spec_mag_clean = torch.maximum(spec_mag - noise_estimate, torch.zeros_like(spec_mag))
            
            # é‡å»ºç›¸ä½
            phase = torch.angle(spec)
            spec_clean = spec_mag_clean * torch.exp(1j * phase)
            
            # åè½‰ STFT
            waveform = torch.istft(
                spec_clean,
                n_fft=n_fft,
                hop_length=hop_length,
                window=torch.hann_window(n_fft).to(device),
                length=waveform.size(-1)
            )
            waveform = waveform.unsqueeze(0)
        
        if AUDIO_PREPROCESSING["normalize_volume"]:
            # éŸ³é‡æ­£è¦åŒ–
            waveform = waveform / torch.max(torch.abs(waveform))
        
        # ç§»å› CPU ä¸¦å„²å­˜
        waveform = waveform.cpu()
        output_path = audio_path.replace('.wav', '_processed.wav')
        torchaudio.save(output_path, waveform, AUDIO_SAMPLE_RATE)
        
        print(f"âœ… éŸ³è¨Šé è™•ç†å®Œæˆ: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"âŒ éŸ³è¨Šé è™•ç†å¤±æ•—: {e}")
        return audio_path

# æ„å‚³ç§‘æŠ€ API è¨­å®š (æ ¹æ“š TauPhahJi-BangTsam æ–‡æª”)
ITHUAN_API = {
    "æ¨™éŸ³æœå‹™": {
        "ç¶²åŸŸ": "https://hokbu.ithuan.tw",
        "ç«¯é»": "/tau",
        "æ–¹æ³•": "POST",
        "å…§å®¹é¡å‹": "application/x-www-form-urlencoded"
    },
    "æ•´æ®µèªéŸ³åˆæˆ": {
        "ç¶²åŸŸ": "https://hokbu.ithuan.tw",
        "ç«¯é»": "/bangtsam",
        "æ–¹æ³•": "GET",
        "å…§å®¹é¡å‹": "application/x-www-form-urlencoded"
    },
    "å–®è©èªéŸ³åˆæˆ": {
        "ç¶²åŸŸ": "https://hokbu.ithuan.tw",
        "ç«¯é»": "/huan",
        "æ–¹æ³•": "GET",
        "å…§å®¹é¡å‹": "application/x-www-form-urlencoded"
    }
}

# APIä½¿ç”¨é™åˆ¶
API_LIMITS = {
    "æ¯åˆ†é˜ä¸‹è¼‰é™åˆ¶": 3,  # æ¯IPæ¯åˆ†é˜æœ€å¤š3æ¬¡éŸ³æª”ä¸‹è¼‰
    "æ–‡å­—é•·åº¦é™åˆ¶": 200,   # å»ºè­°å–®æ¬¡æŸ¥è©¢ä¸è¶…é200å­—
    "é¿å…åŒæ™‚è«‹æ±‚": True    # é¿å…åŒæ™‚ç™¼é€å¤šå€‹è«‹æ±‚
}

def find_ffmpeg():
    """å°‹æ‰¾ FFmpeg åŸ·è¡Œæª”"""
    possible_paths = [
        "./ffmpeg_bin/ffmpeg.exe",
        "ffmpeg",
        "ffmpeg.exe",
        "C:/ffmpeg/bin/ffmpeg.exe",
    ]
    
    for path in possible_paths:
        try:
            result = subprocess.run([path, "-version"], 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=5)
            if result.returncode == 0:
                return path
        except (FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    return None

def init_taiwanese_model():
    """åˆå§‹åŒ–å°èªèªéŸ³è¾¨è­˜æ¨¡å‹"""
    global taiwanese_processor, taiwanese_model, device, ffmpeg_path
    
    debug_print("åˆå§‹åŒ–å°èªèªéŸ³è¾¨è­˜ç³»çµ±...")
    
    # æª¢æŸ¥è¨­å‚™
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if torch.cuda.is_available():
        print(f"ğŸ® ä½¿ç”¨ GPU åŠ é€Ÿ: {torch.cuda.get_device_name(0)}")
        print(f"   CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        # å•Ÿç”¨ CUDA å„ªåŒ–
        torch.backends.cudnn.benchmark = True
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
    else:
        print("âš ï¸ æœªæª¢æ¸¬åˆ° GPUï¼Œä½¿ç”¨ CPU æ¨¡å¼")
    
    debug_print(f"è¨­å‚™: {device}")
    
    # æª¢æŸ¥ FFmpeg
    ffmpeg_path = find_ffmpeg()
    debug_print(f"FFmpeg: {ffmpeg_path if ffmpeg_path else 'æœªæ‰¾åˆ°'}")
    
    # å°èªå°ˆé–€æ¨¡å‹
    model_name = "NUTN-KWS/Whisper-Taiwanese-model-v0.5"
    
    debug_print("è¼‰å…¥å°èªå°ˆé–€æ¨¡å‹...")
    debug_print(f"å˜—è©¦è¼‰å…¥: {model_name}")
    
    try:
        # ä½¿ç”¨ float16 å’Œå„ªåŒ–é…ç½®
        load_config = {
            "torch_dtype": torch.float16 if device == "cuda" else torch.float32,
            "low_cpu_mem_usage": True,
            "use_safetensors": True
        }
        
        processor = WhisperProcessor.from_pretrained(model_name)
        model = WhisperForConditionalGeneration.from_pretrained(
            model_name,
            **load_config
        )
        
        # ç§»å‹•åˆ° GPU ä¸¦å„ªåŒ–
        model = model.to(device)
        if device == "cuda":
            model.eval()  # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
        
        taiwanese_processor = processor
        taiwanese_model = model
        
        debug_print(f"âœ… æˆåŠŸè¼‰å…¥å°èªæ¨¡å‹: {model_name}")
        return True
            
    except Exception as e:
        debug_print(f"è¼‰å…¥å°èªæ¨¡å‹å¤±æ•—: {e}")
        taiwanese_processor = None
        taiwanese_model = None
        return False

def convert_webm_with_ffmpeg(webm_file):
    """ä½¿ç”¨ FFmpeg å°‡ webm è½‰æ›ç‚º wav"""
    global ffmpeg_path
    
    if not ffmpeg_path:
        debug_print("FFmpeg ä¸å¯ç”¨")
        return None
    
    try:
        debug_print(f"ä½¿ç”¨ FFmpeg è½‰æ›: {webm_file}")
        
        # æª¢æŸ¥è¼¸å…¥æª”æ¡ˆ
        if not os.path.exists(webm_file):
            debug_print(f"è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨: {webm_file}")
            return None
            
        # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
        temp_wav = os.path.join(
            os.path.dirname(webm_file),
            f"temp_{int(time.time()*1000)}.wav"
        )
        
        # FFmpeg å‘½ä»¤
        cmd = [
            ffmpeg_path,
            '-y',  # è¦†å¯«è¼¸å‡ºæª”æ¡ˆ
            '-i', webm_file,  # è¼¸å…¥
            '-acodec', 'pcm_s16le',  # éŸ³è¨Šç·¨ç¢¼
            '-ar', '16000',  # æ¡æ¨£ç‡
            '-ac', '1',  # å–®è²é“
            '-hide_banner',  # éš±è—æ©«å¹…
            '-loglevel', 'error',  # åªé¡¯ç¤ºéŒ¯èª¤
            temp_wav  # è¼¸å‡º
        ]
        
        debug_print(f"åŸ·è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # åŸ·è¡Œè½‰æ›
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            if os.path.exists(temp_wav) and os.path.getsize(temp_wav) > 0:
                debug_print(f"FFmpeg è½‰æ›æˆåŠŸ: {temp_wav}")
                return temp_wav
            else:
                debug_print("è½‰æ›å¾Œçš„æª”æ¡ˆç„¡æ•ˆ")
                return None
        else:
            debug_print(f"FFmpeg è½‰æ›å¤±æ•—: {result.stderr}")
            return None
            
    except Exception as e:
        debug_print(f"FFmpeg è½‰æ›å‡ºéŒ¯: {e}")
        return None

def transcribe_taiwanese_audio(audio_file_path):
    """å°èªèªéŸ³è¾¨è­˜"""
    global taiwanese_processor, taiwanese_model, device
    
    try:
        debug_print(f"é–‹å§‹å°èªèªéŸ³è¾¨è­˜: {audio_file_path}")
        
        if not os.path.exists(audio_file_path):
            debug_print("éŸ³æª”ä¸å­˜åœ¨")
            return ""
        
        # è¼‰å…¥éŸ³æª”
        audio_data = None
        sr = 16000
        
        if audio_file_path.lower().endswith('.webm'):
            debug_print("è™•ç† WebM æ ¼å¼...")
            converted_path = convert_webm_with_ffmpeg(audio_file_path)
            if converted_path:
                try:
                    audio_data, sr = librosa.load(converted_path, sr=16000, mono=True)
                    os.unlink(converted_path)  # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                    debug_print("WebM è½‰æ›æˆåŠŸ")
                except Exception as e:
                    debug_print(f"WebM éŸ³æª”è¼‰å…¥å¤±æ•—: {e}")
                    if os.path.exists(converted_path):
                        os.unlink(converted_path)
                    return ""
            else:
                debug_print("WebM è½‰æ›å¤±æ•—")
                return ""
        else:
            try:
                audio_data, sr = librosa.load(audio_file_path, sr=16000, mono=True)
                debug_print("éŸ³æª”è¼‰å…¥æˆåŠŸ")
            except Exception as e:
                debug_print(f"éŸ³æª”è¼‰å…¥å¤±æ•—: {e}")
                return ""
        
        if audio_data is None or len(audio_data) == 0:
            debug_print("éŸ³æª”è³‡æ–™ç‚ºç©º")
            return ""
        
        debug_print(f"éŸ³æª”è³‡è¨Š: é•·åº¦={len(audio_data)}, å–æ¨£ç‡={sr}")
        
        # ä½¿ç”¨å°èª transformers æ¨¡å‹
        try:
            debug_print("ä½¿ç”¨å°èª transformers æ¨¡å‹...")
            
            # è¨ˆç®—ç‰¹å¾µ
            input_features = taiwanese_processor.feature_extractor(
                audio_data, 
                sampling_rate=sr,
                return_tensors="pt"
            )
            
            # ç§»å‹•åˆ° GPU
            input_features = input_features.to(device)
            
            # ä½¿ç”¨æ··åˆç²¾åº¦æ¨ç†
            with torch.cuda.amp.autocast():
                generated_ids = taiwanese_model.generate(
                    input_features.input_features,
                    max_length=225,
                    language="zh",
                    task="transcribe",
                    num_beams=1,
                    do_sample=False
                )
                
                transcription = taiwanese_processor.batch_decode(
                    generated_ids,
                    skip_special_tokens=True
                )[0].strip()
            
            # æ¸…ç† GPU è¨˜æ†¶é«”
            if device == "cuda":
                torch.cuda.empty_cache()
            
            debug_print(f"è¾¨è­˜æˆåŠŸ: '{transcription}'")
            return transcription
            
        except Exception as e:
            debug_print(f"è¾¨è­˜å¤±æ•—: {e}")
            return ""
            
    except Exception as e:
        debug_print(f"èªéŸ³è¾¨è­˜å‡ºéŒ¯: {e}")
        return ""

def clean_transcription_result(text):
    """æ¸…ç†è¾¨è­˜çµæœæ–‡å­—"""
    if not text:
        return text
        
    # ç§»é™¤å¤šé¤˜çš„ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    
    # ç§»é™¤ç‰¹æ®Šæ¨™è¨˜
    text = re.sub(r'<[^>]+>', '', text)
    
    # ä¿®æ­£å¸¸è¦‹éŒ¯èª¤
    text = text.replace('å°èª:', '')
    text = text.replace('å°ç¾…:', '')
    
    return text.strip()

@performance_timer("å°èªæ¨™éŸ³è½‰æ›")
def get_taiwanese_pronunciation(text):
    """èª¿ç”¨æ„å‚³ç§‘æŠ€æ¨™éŸ³ API"""
    try:
        debug_print(f"ç²å–å°èªæ¨™éŸ³: '{text}'")
        
        if len(text) > API_LIMITS["æ–‡å­—é•·åº¦é™åˆ¶"]:
            debug_print("æ–‡å­—éé•·ï¼Œæˆªæ–·è™•ç†")
            text = text[:API_LIMITS["æ–‡å­—é•·åº¦é™åˆ¶"]]
        
        api_config = ITHUAN_API["æ¨™éŸ³æœå‹™"]
        url = f"{api_config['ç¶²åŸŸ']}{api_config['ç«¯é»']}"
        
        data = {'taibun': text.strip()}
        
        debug_print(f"API è«‹æ±‚: {url}")
        
        api_start = time.time()
        response = requests.post(
            url,
            data=data,
            headers={
                'Content-Type': api_config['å…§å®¹é¡å‹'],
                'User-Agent': 'TaiwaneseVoiceChat/1.0'
            },
            timeout=15
        )
        api_time = time.time() - api_start
        log_step_time("ã€€â”œâ”€ æ„å‚³æ¨™éŸ³API", api_time, f"ç‹€æ…‹: {response.status_code}")
        
        debug_print(f"å›æ‡‰ç‹€æ…‹: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            
            if 'kiatko' in result and result['kiatko']:
                romanization_parts = []
                for item in result['kiatko']:
                    if 'KIP' in item and item['KIP']:
                        romanization_parts.append(item['KIP'])
                
                if romanization_parts:
                    romanization = ' '.join(romanization_parts)
                    debug_print(f"ç¾…é¦¬æ‹¼éŸ³: {romanization}")
                    return romanization, result.get('åˆ†è©', text), result['kiatko']
            
            if 'åˆ†è©' in result:
                segmented = result['åˆ†è©']
                debug_print(f"åˆ†è©çµæœ: {segmented}")
                return segmented, segmented, []
        
        debug_print("API è¿”å›ç•°å¸¸")
        return text, text, []
        
    except Exception as e:
        debug_print(f"æ¨™éŸ³ API å¤±æ•—: {e}")
        return text, text, []

def text_to_speech_ithuan_full_sentence(è…”å£, åˆ†è©):
    """æ•´æ®µèªéŸ³åˆæˆï¼ˆæŒ‰ç…§ TauPhahJi-BangTsam è¦ç¯„ï¼‰"""
    try:
        print(f"ğŸ”Š æ•´æ®µèªéŸ³åˆæˆ: è…”å£='{è…”å£}', åˆ†è©='{åˆ†è©}'")
        
        # æ ¹æ“šæ–‡æª”è¦ç¯„æ§‹å»ºAPIè«‹æ±‚
        api_config = ITHUAN_API["æ•´æ®µèªéŸ³åˆæˆ"]
        base_url = f"{api_config['ç¶²åŸŸ']}{api_config['ç«¯é»']}"
        
        # GET è«‹æ±‚åƒæ•¸
        params = {
            'æŸ¥è©¢è…”å£': è…”å£,
            'æŸ¥è©¢èªå¥': åˆ†è©
        }
        
        print(f"   ğŸ“¡ API ç«¯é»: {base_url}")
        print(f"   ğŸ“¤ è«‹æ±‚åƒæ•¸: {params}")
        print(f"   ğŸ”§ è«‹æ±‚æ–¹æ³•: {api_config['æ–¹æ³•']}")
        
        # æ‰‹å‹•æ§‹å»º URL ä»¥ç¢ºä¿æ­£ç¢ºç·¨ç¢¼ï¼ˆæŒ‰ç…§æ–‡æª”ç¯„ä¾‹ï¼‰
        encoded_params = urlencode(params, safe='', encoding='utf-8')
        full_url = f"{base_url}?{encoded_params}"
        print(f"   ğŸŒ å®Œæ•´URL: {full_url}")
        
        # ç™¼é€ GET è«‹æ±‚
        response = requests.get(
            full_url,
            timeout=30,
            headers={
                'User-Agent': 'TaiwaneseVoiceChat/1.0',
                'Accept': 'audio/wav, audio/*, */*',
                'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8'
            }
        )
        
        print(f"   ğŸ“¥ å›æ‡‰ç‹€æ…‹: {response.status_code}")
        print(f"   ğŸ“‹ Content-Type: {response.headers.get('content-type', 'unknown')}")
        print(f"   ğŸ“ å›æ‡‰å¤§å°: {len(response.content)} bytes")
        
        # ä¸ç®¡ç‹€æ…‹ç¢¼å¦‚ä½•ï¼Œéƒ½æª¢æŸ¥æ˜¯å¦æœ‰éŸ³æª”æ•¸æ“š
        if len(response.content) > 100:
            content_type = response.headers.get('content-type', '').lower()
            print(f"   ğŸ” æª¢æŸ¥éŸ³æª”å…§å®¹: å¤§å°={len(response.content)}, type='{content_type}'")
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºéŸ³è¨Šå…§å®¹ï¼ˆæ›´å¯¬é¬†çš„åˆ¤æ–·ï¼‰
            is_audio = (
                'audio' in content_type or 
                len(response.content) > 1000 or
                response.content.startswith(b'RIFF') or  # WAVæª”æ¡ˆæ¨™é ­
                response.content.startswith(b'ID3') or   # MP3æª”æ¡ˆæ¨™é ­
                response.content.startswith(b'\xff\xfb') # MP3æª”æ¡ˆæ¨™é ­è®Šç¨®
            )
            
            if is_audio:
                # å„²å­˜éŸ³æª”ï¼ˆå³ä½¿æ˜¯404ä¹Ÿå˜—è©¦ä¿å­˜ï¼‰
                timestamp = int(time.time())
                output_file = f"static/tts_full_{timestamp}.wav"
                
                # ç¢ºä¿ static ç›®éŒ„å­˜åœ¨
                os.makedirs("static", exist_ok=True)
                
                with open(output_file, 'wb') as f:
                    f.write(response.content)
                
                print(f"   âœ… ç™¼ç¾éŸ³æª”æ•¸æ“šä¸¦ä¿å­˜: {output_file} (ç‹€æ…‹ç¢¼: {response.status_code})")
                return output_file
            else:
                print(f"   âš ï¸ å›æ‡‰ä¸åƒéŸ³è¨Šæ ¼å¼")
                # å¦‚æœæ˜¯æ–‡å­—å›æ‡‰ï¼Œé¡¯ç¤ºå…§å®¹
                if response.content:
                    try:
                        text_content = response.content.decode('utf-8', errors='ignore')[:200]
                        print(f"   ğŸ“‹ æ–‡å­—å›æ‡‰: {text_content}")
                    except:
                        print(f"   ğŸ“‹ äºŒé€²ä½å›æ‡‰: {response.content[:50]}")
        else:
            print(f"   âš ï¸ å›æ‡‰å¤ªå°ï¼ˆ{len(response.content)} bytesï¼‰ï¼Œå¯èƒ½ä¸æ˜¯éŸ³æª”")
            if response.content:
                try:
                    text_content = response.content.decode('utf-8', errors='ignore')[:200]
                    print(f"   ğŸ“‹ å°å›æ‡‰å…§å®¹: {text_content}")
                except:
                    print(f"   ğŸ“‹ å°å›æ‡‰äºŒé€²ä½: {response.content}")
        
        return None
        
    except Exception as e:
        print(f"   âŒ æ•´æ®µèªéŸ³åˆæˆå¤±æ•—: {e}")
        return None

def text_to_speech_ithuan_single_word(ç¾…é¦¬æ‹¼éŸ³):
    """å–®è©èªéŸ³åˆæˆï¼ˆæŒ‰ç…§ TauPhahJi-BangTsam è¦ç¯„ï¼‰"""
    try:
        print(f"ğŸ”Š å–®è©èªéŸ³åˆæˆ: '{ç¾…é¦¬æ‹¼éŸ³}'")
        
        # æ ¹æ“šæ–‡æª”è¦ç¯„æ§‹å»ºAPIè«‹æ±‚
        api_config = ITHUAN_API["å–®è©èªéŸ³åˆæˆ"]
        base_url = f"{api_config['ç¶²åŸŸ']}{api_config['ç«¯é»']}"
        
        # GET è«‹æ±‚åƒæ•¸
        params = {
            'taibun': ç¾…é¦¬æ‹¼éŸ³
        }
        
        print(f"   ğŸ“¡ API ç«¯é»: {base_url}")
        print(f"   ğŸ“¤ è«‹æ±‚åƒæ•¸: {params}")
        print(f"   ğŸ”§ è«‹æ±‚æ–¹æ³•: {api_config['æ–¹æ³•']}")
        
        # æŒ‰ç…§æ–‡æª”ç¯„ä¾‹æ§‹å»ºURL
        # encodeURI + encodeURIComponent
        encoded_taibun = quote(ç¾…é¦¬æ‹¼éŸ³, safe='')
        full_url = f"{base_url}?taibun={encoded_taibun}"
        print(f"   ğŸŒ å®Œæ•´URL: {full_url}")
        
        # ç™¼é€ GET è«‹æ±‚
        response = requests.get(
            full_url,
            timeout=30,
            headers={
                'User-Agent': 'TaiwaneseVoiceChat/1.0',
                'Accept': 'audio/wav, audio/*, */*',
                'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8'
            }
        )
        
        print(f"   ğŸ“¥ å›æ‡‰ç‹€æ…‹: {response.status_code}")
        print(f"   ğŸ“‹ Content-Type: {response.headers.get('content-type', 'unknown')}")
        print(f"   ğŸ“ å›æ‡‰å¤§å°: {len(response.content)} bytes")
        
        # ä¸ç®¡ç‹€æ…‹ç¢¼å¦‚ä½•ï¼Œéƒ½æª¢æŸ¥æ˜¯å¦æœ‰éŸ³æª”æ•¸æ“š
        if len(response.content) > 100:
            content_type = response.headers.get('content-type', '').lower()
            print(f"   ğŸ” æª¢æŸ¥éŸ³æª”å…§å®¹: å¤§å°={len(response.content)}, type='{content_type}'")
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºéŸ³è¨Šå…§å®¹ï¼ˆæ›´å¯¬é¬†çš„åˆ¤æ–·ï¼‰
            is_audio = (
                'audio' in content_type or 
                len(response.content) > 1000 or
                response.content.startswith(b'RIFF') or  # WAVæª”æ¡ˆæ¨™é ­
                response.content.startswith(b'ID3') or   # MP3æª”æ¡ˆæ¨™é ­
                response.content.startswith(b'\xff\xfb') # MP3æª”æ¡ˆæ¨™é ­è®Šç¨®
            )
            
            if is_audio:
                # å„²å­˜éŸ³æª”ï¼ˆå³ä½¿æ˜¯404ä¹Ÿå˜—è©¦ä¿å­˜ï¼‰
                timestamp = int(time.time())
                # æ¸…ç†æª”åï¼Œç§»é™¤ä¸åˆæ³•å­—ç¬¦
                import re
                safe_filename = re.sub(r'[<>:"/\\|?*,]', '_', ç¾…é¦¬æ‹¼éŸ³.replace(' ', '_').replace('-', '_'))[:20]
                output_file = f"static/tts_word_{safe_filename}_{timestamp}.wav"
                
                # ç¢ºä¿ static ç›®éŒ„å­˜åœ¨
                os.makedirs("static", exist_ok=True)
                
                with open(output_file, 'wb') as f:
                    f.write(response.content)
                
                print(f"   âœ… ç™¼ç¾éŸ³æª”æ•¸æ“šä¸¦ä¿å­˜: {output_file} (ç‹€æ…‹ç¢¼: {response.status_code})")
                return output_file
            else:
                print(f"   âš ï¸ å›æ‡‰ä¸åƒéŸ³è¨Šæ ¼å¼")
                # å¦‚æœæ˜¯æ–‡å­—å›æ‡‰ï¼Œé¡¯ç¤ºå…§å®¹
                if response.content:
                    try:
                        text_content = response.content.decode('utf-8', errors='ignore')[:200]
                        print(f"   ğŸ“‹ æ–‡å­—å›æ‡‰: {text_content}")
                    except:
                        print(f"   ğŸ“‹ äºŒé€²ä½å›æ‡‰: {response.content[:50]}")
        else:
            print(f"   âš ï¸ å›æ‡‰å¤ªå°ï¼ˆ{len(response.content)} bytesï¼‰ï¼Œå¯èƒ½ä¸æ˜¯éŸ³æª”")
            if response.content:
                try:
                    text_content = response.content.decode('utf-8', errors='ignore')[:200]
                    print(f"   ğŸ“‹ å°å›æ‡‰å…§å®¹: {text_content}")
                except:
                    print(f"   ğŸ“‹ å°å›æ‡‰äºŒé€²ä½: {response.content}")
        
        return None
        
    except Exception as e:
        print(f"   âŒ å–®è©èªéŸ³åˆæˆå¤±æ•—: {e}")
        return None



@performance_timer("LLMæ™ºèƒ½å°è©±")
def chat_with_ollama(text):
    """èˆ‡ Ollama LLM å°è©±"""
    try:
        debug_print(f"LLM å°è©±è™•ç†: '{text}'")
        
        # ä½¿ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œé™åˆ¶15å­—ä»¥å…§
        prompt = f"""ä½ æ˜¯ä¸€å€‹å°ç£äººå·¥æ™ºæ…§åŠ©ç†ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚æ³¨æ„ï¼š
1. ä½¿ç”¨è‡ªç„¶ã€æµæš¢çš„ç¹é«”ä¸­æ–‡
2. ä¸è¦ä½¿ç”¨ç°¡é«”å­—
3. å›ç­”å¿…é ˆåœ¨15å€‹å­—ä»¥å…§
4. ä¿æŒå°è©±çš„é€£è²«æ€§å’Œé‚è¼¯æ€§

ç”¨æˆ¶ï¼š{text}

åŠ©ç†ï¼š"""

        api_start = time.time()
        
        # ä½¿ç”¨æ€§èƒ½é…ç½®çš„å„ªåŒ–åƒæ•¸
        if PERFORMANCE_CONFIG_AVAILABLE:
            config = get_current_config()
            llm_options = config["llm_config"].copy()
            timeout = llm_options.pop("timeout", 15)
            debug_print(f"ä½¿ç”¨æ€§èƒ½é…ç½®LLMåƒæ•¸: {llm_options}")
        else:
            # å‚™ç”¨å„ªåŒ–åƒæ•¸
            llm_options = {
                'temperature': 0.7,
                'top_p': 0.9,
                'top_k': 40,
                'repeat_penalty': 1.1,
                'num_thread': 4,
                'num_batch': 512,
            }
            timeout = 15
        
        response = requests.post('http://localhost:11434/api/generate', 
            json={
                'model': 'gemma3:4b',
                'prompt': prompt,
                'stream': False,
                'options': llm_options
            },
            timeout=timeout
        )
        api_time = time.time() - api_start
        log_step_time("ã€€â”œâ”€ Ollama APIè«‹æ±‚", api_time)
        
        if response.status_code == 200:
            result = response.json()
            reply = result.get('response', '').strip()
            
            # æ¸…ç†å›æ‡‰ï¼Œä½†ä¿ç•™æ¨™é»ç¬¦è™Ÿ
            cleaned_reply = re.sub(r'[^\u4e00-\u9fffï¼ï¼Ÿã€‚ï¼Œã€ï¼šï¼›ã€Œã€ã€ã€ï¼ˆï¼‰]', '', reply)
            
            # å¦‚æœæ¸…ç†å¾Œçš„å›æ‡‰ç‚ºç©ºï¼Œè¿”å›é è¨­å›æ‡‰
            if not cleaned_reply:
                final_reply = "å¥½çš„ï¼"
            else:
                # é™åˆ¶å›æ‡‰åœ¨15å€‹å­—ä»¥å…§
                if len(cleaned_reply) > 15:
                    final_reply = cleaned_reply[:15]
                else:
                    final_reply = cleaned_reply
                
            debug_print(f"LLM å›æ‡‰: '{final_reply}'")
            return final_reply
        else:
            debug_print(f"LLM API å¤±æ•—: {response.status_code}")
            return "å¥½çš„ï¼"
            
    except Exception as e:
        debug_print(f"LLM å°è©±å¤±æ•—: {e}")
        return "å¥½çš„ï¼"

@performance_timer("æ„å‚³ç§‘æŠ€TTSæœå‹™")
def text_to_speech_ithuan(text, kiatko_data=None):
    """æ„å‚³ç§‘æŠ€ TTS ä¸»å‡½æ•¸ï¼ˆæ•´åˆæ•´æ®µå’Œå–®è©åˆæˆï¼‰"""
    print(f"ğŸ”Š æ„å‚³ç§‘æŠ€ TTS é–‹å§‹: '{text}'")
    
    # å„ªå…ˆå˜—è©¦æ•´æ®µèªéŸ³åˆæˆ
    print("ğŸ¯ å˜—è©¦æ•´æ®µèªéŸ³åˆæˆ...")
    full_audio = text_to_speech_ithuan_full_sentence("é–©å—èª", text)
    if full_audio:
        print(f"âœ… æ•´æ®µèªéŸ³åˆæˆæˆåŠŸ: {full_audio}")
        return full_audio
    
    # å¦‚æœæ•´æ®µå¤±æ•—ï¼Œä¸”æœ‰åˆ†è©è³‡æ–™ï¼Œå˜—è©¦åˆæˆç¬¬ä¸€å€‹è©
    if kiatko_data and len(kiatko_data) > 0:
        print("ğŸ¯ å˜—è©¦å–®è©èªéŸ³åˆæˆ...")
        first_word = kiatko_data[0]
        if 'KIP' in first_word and first_word['KIP']:
            single_audio = text_to_speech_ithuan_single_word(first_word['KIP'])
            if single_audio:
                print(f"âœ… å–®è©èªéŸ³åˆæˆæˆåŠŸ: {single_audio}")
                return single_audio
    
    print("âŒ æ‰€æœ‰æ„å‚³ç§‘æŠ€ TTS æ–¹æ¡ˆéƒ½å¤±æ•—")
    return None

@app.route('/')
def index():
    """ä¸»é é¢"""
    return render_template('index.html')

@app.route('/process_audio', methods=['POST'])
def process_audio():
    """è™•ç†èªéŸ³æª”æ¡ˆ"""
    global remote_tts_service, romanization_converter
    
    # ç¸½é«”è¨ˆæ™‚é–‹å§‹
    total_start_time = time.time()
    print(f"ğŸš€ é–‹å§‹è™•ç†èªéŸ³è«‹æ±‚ - {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # å„æ­¥é©Ÿè¨ˆæ™‚çµ±è¨ˆ
    step_times = {}
    
    try:
        # æ­¥é©Ÿ0: è«‹æ±‚é©—è­‰
        step_start = time.time()
        if 'audio' not in request.files:
            return jsonify({'error': 'æ²’æœ‰æ”¶åˆ°éŸ³æª”'}), 400
            
        audio_file = request.files['audio']
        
        if audio_file.filename == '':
            return jsonify({'error': 'éŸ³æª”åç¨±ç‚ºç©º'}), 400
        step_times['è«‹æ±‚é©—è­‰'] = time.time() - step_start
        log_step_time("è«‹æ±‚é©—è­‰", step_times['è«‹æ±‚é©—è­‰'])
            
        # æ­¥é©Ÿ1: éŸ³æª”ä¿å­˜
        step_start = time.time()
        # å»ºç«‹æœ¬åœ°ä¿å­˜ç›®éŒ„
        os.makedirs("uploads", exist_ok=True)
        
        # æ±ºå®šæª”æ¡ˆå‰¯æª”å
        content_type = audio_file.content_type or 'audio/webm'
        if 'webm' in content_type:
            suffix = '.webm'
        elif 'wav' in content_type:
            suffix = '.wav'
        elif 'mp3' in content_type:
            suffix = '.mp3'
        else:
            suffix = '.audio'
        
        # ä¿å­˜éŸ³æª”
        timestamp = int(time.time() * 1000)
        local_filename = f"uploads/recording_{timestamp}{suffix}"
        
        audio_file.seek(0)
        audio_data = audio_file.read()
        
        if len(audio_data) == 0:
            return jsonify({'error': 'éŸ³æª”æ•¸æ“šç‚ºç©º'}), 400
        
        try:
            with open(local_filename, 'wb') as f:
                f.write(audio_data)
            debug_print(f"éŸ³æª”ä¿å­˜æˆåŠŸ: {local_filename}")
        except Exception as e:
            debug_print(f"éŸ³æª”ä¿å­˜å¤±æ•—: {e}")
            return jsonify({'error': 'éŸ³æª”ä¿å­˜å¤±æ•—'}), 500
        
        if not os.path.exists(local_filename) or os.path.getsize(local_filename) == 0:
            return jsonify({'error': 'ä¿å­˜çš„éŸ³æª”ç„¡æ•ˆ'}), 400
        
        step_times['éŸ³æª”ä¿å­˜'] = time.time() - step_start
        log_step_time("éŸ³æª”ä¿å­˜", step_times['éŸ³æª”ä¿å­˜'], f"æª”æ¡ˆå¤§å°: {len(audio_data)} bytes")
        
        try:
            debug_print("é–‹å§‹å°èªèªéŸ³å°è©±è™•ç†")
            
            # æ­¥é©Ÿ2: éŸ³æª”æ ¼å¼è½‰æ›ï¼ˆå¦‚æœéœ€è¦ï¼‰
            step_start = time.time()
            audio_path = local_filename
            if suffix != '.wav':
                converted_path = convert_webm_with_ffmpeg(local_filename)
                if converted_path:
                    audio_path = converted_path
                else:
                    return jsonify({'error': 'éŸ³æª”æ ¼å¼è½‰æ›å¤±æ•—'}), 400
            step_times['æ ¼å¼è½‰æ›'] = time.time() - step_start
            log_step_time("éŸ³æª”æ ¼å¼è½‰æ›", step_times['æ ¼å¼è½‰æ›'])
            
            # æ­¥é©Ÿ3: å°èªèªéŸ³è¾¨è­˜
            step_start = time.time()
            recognized_text = transcribe_taiwanese_audio(audio_path)
            step_times['èªéŸ³è¾¨è­˜'] = time.time() - step_start
            log_step_time("å°èªèªéŸ³è¾¨è­˜", step_times['èªéŸ³è¾¨è­˜'], f"è¾¨è­˜çµæœ: '{recognized_text}'")
            
            if not recognized_text:
                return jsonify({'error': 'ç„¡æ³•è¾¨è­˜å°èªèªéŸ³å…§å®¹'}), 400
            
            # æ­¥é©Ÿ4: LLM å°è©±
            step_start = time.time()
            ai_response = chat_with_ollama(recognized_text)
            step_times['LLMå°è©±'] = time.time() - step_start
            log_step_time("LLMæ™ºèƒ½å°è©±", step_times['LLMå°è©±'], f"AIå›æ‡‰: '{ai_response}'")
            
            # æ­¥é©Ÿ5: å°èªæ¨™éŸ³è½‰æ›
            step_start = time.time()
            romanization, segmented, kiatko_data = get_taiwanese_pronunciation(ai_response)
            step_times['æ¨™éŸ³è½‰æ›'] = time.time() - step_start
            log_step_time("å°èªæ¨™éŸ³è½‰æ›", step_times['æ¨™éŸ³è½‰æ›'], f"ç¾…é¦¬æ‹¼éŸ³: '{romanization}'")
            
            # æ­¥é©Ÿ6: æ ¼å¼è½‰æ›ï¼ˆç¾…é¦¬æ‹¼éŸ³è½‰æ•¸å­—èª¿ï¼‰
            step_start = time.time()
            if romanization_converter:
                numeric_tone_text = romanization_converter.convert_to_numeric_tone(romanization)
                debug_print(f"æ ¼å¼è½‰æ›: '{romanization}' -> '{numeric_tone_text}'")
            else:
                numeric_tone_text = romanization
                debug_print(f"è·³éæ ¼å¼è½‰æ›: '{romanization}'")
            step_times['æ ¼å¼è½‰æ›'] = time.time() - step_start
            log_step_time("ç¾…é¦¬æ‹¼éŸ³æ ¼å¼è½‰æ›", step_times['æ ¼å¼è½‰æ›'], f"æ•¸å­—èª¿æ ¼å¼: '{numeric_tone_text}'")
            
            # æ­¥é©Ÿ7: æ–‡å­—è½‰èªéŸ³ï¼ˆä½¿ç”¨è‡ªè¨“ç·´é ç«¯ TTS æœå‹™ï¼‰
            step_start = time.time()
            print(f"\nğŸ”Š æ­¥é©Ÿ7: å°èªèªéŸ³åˆæˆ")
            print(f"ä½¿ç”¨è‡ªè¨“ç·´é ç«¯ TTS æœå‹™ (163.13.202.125:5000)")
            audio_file_path = None
            if remote_tts_service:
                audio_file_path = remote_tts_service.generate_speech(numeric_tone_text)
            else:
                print("âš ï¸ é ç«¯TTSæœå‹™æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨æ„å‚³ç§‘æŠ€TTSä½œç‚ºå‚™ç”¨")
                audio_file_path = text_to_speech_ithuan(romanization, kiatko_data)
            step_times['èªéŸ³åˆæˆ'] = time.time() - step_start
            log_step_time("å°èªèªéŸ³åˆæˆ", step_times['èªéŸ³åˆæˆ'], f"éŸ³æª”: {audio_file_path if audio_file_path else 'å¤±æ•—'}")
            
            if audio_file_path:
                print(f"ğŸ”Š TTS æˆåŠŸ: {audio_file_path}")
            else:
                print("âš ï¸ TTS å¤±æ•—")
            
            # è¨ˆç®—ç¸½è€—æ™‚
            total_time = time.time() - total_start_time
            
            # æ­¥é©Ÿ8: è¿”å›çµæœ
            print(f"\nâœ… å°èªèªéŸ³å°è©±è™•ç†å®Œæˆ")
            print(f"ğŸ¯ ç¸½è™•ç†æ™‚é–“: {total_time:.3f}ç§’")
            print("ğŸ“Š å„æ­¥é©Ÿè€—æ™‚çµ±è¨ˆ:")
            for step_name, duration in step_times.items():
                percentage = (duration / total_time) * 100
                print(f"   â€¢ {step_name}: {duration:.3f}ç§’ ({percentage:.1f}%)")
            
            # ç”Ÿæˆæ€§èƒ½å„ªåŒ–å»ºè­°
            optimization_suggestions = []
            if PERFORMANCE_CONFIG_AVAILABLE:
                optimization_suggestions = get_optimization_suggestions(step_times, total_time)
            
            result = {
                'success': True,
                'transcription': recognized_text,
                'ai_response': ai_response,
                'romanization': romanization,
                'numeric_tone_text': numeric_tone_text,
                'segmented': segmented,
                'kiatko_count': len(kiatko_data),
                'audio_url': f'/{audio_file_path}' if audio_file_path else None,
                'api_info': f"ä½¿ç”¨è‡ªè¨“ç·´é ç«¯ TTS æœå‹™ (163.13.202.125:5000)" if remote_tts_service and audio_file_path else "ä½¿ç”¨æ„å‚³ç§‘æŠ€TTSä½œç‚ºå‚™ç”¨",
                'performance_stats': {
                    'total_time': total_time,
                    'step_times': step_times,
                    'bottleneck': max(step_times, key=step_times.get) if step_times else None,
                    'mode': PERFORMANCE_MODE,
                    'suggestions': optimization_suggestions
                }
            }
            
            debug_print("å°èªèªéŸ³å°è©±è™•ç†å®Œæˆ")
            return jsonify(result)
            
        finally:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            try:
                if CLEANUP_FILES:
                    if os.path.exists(local_filename):
                        os.unlink(local_filename)
                        debug_print(f"æ¸…ç†æœ¬åœ°æª”æ¡ˆ: {local_filename}")
                    if audio_path != local_filename and os.path.exists(audio_path):
                        os.unlink(audio_path)
                        debug_print(f"æ¸…ç†è½‰æ›æª”æ¡ˆ: {audio_path}")
            except Exception as e:
                debug_print(f"æ¸…ç†æª”æ¡ˆå¤±æ•—: {e}")
        
    except Exception as e:
        debug_print(f"è™•ç†éŒ¯èª¤: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/test_api')
def test_api():
    """æ¸¬è©¦æ„å‚³ç§‘æŠ€ APIï¼ˆæŒ‰ç…§ TauPhahJi-BangTsam è¦ç¯„ï¼‰"""
    try:
        test_text = "ä½ å¥½å—"
        print(f"ğŸ§ª æ¸¬è©¦æ„å‚³ç§‘æŠ€ API: '{test_text}'")
        print(f"ğŸ“‹ API è¦ç¯„: åŸºæ–¼ TauPhahJi-BangTsam å°ˆæ¡ˆ")
        
        # æ¸¬è©¦æ¨™éŸ³ API
        romanization, segmented, kiatko_data = get_taiwanese_pronunciation(test_text)
        print(f"ğŸ”¤ æ¸¬è©¦æ¨™éŸ³çµæœ: '{romanization}'")
        
        # æ¸¬è©¦ TTS API
        print(f"ğŸ”Š æ¸¬è©¦ TTS è¼¸å…¥: '{romanization}' (ç¾…é¦¬æ‹¼éŸ³)")
        audio_file = text_to_speech_ithuan(romanization, kiatko_data)
        
        result = {
            'test_text': test_text,
            'romanization': romanization,
            'segmented': segmented,
            'kiatko_count': len(kiatko_data),
            'audio_file': audio_file,
            'api_status': 'success' if audio_file else 'failed',
            'api_info': {
                'æ¨™éŸ³æœå‹™': f"{ITHUAN_API['æ¨™éŸ³æœå‹™']['ç¶²åŸŸ']}{ITHUAN_API['æ¨™éŸ³æœå‹™']['ç«¯é»']}",
                'é ç«¯TTS': "æœªé…ç½®" # config.get_remote_tts_display_name() if remote_tts_service and config.is_remote_tts_configured() else "æœªé…ç½®"
            }
        }
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e), 'api_status': 'failed'})

@app.route('/test_remote_tts')
def test_remote_tts():
    """æ¸¬è©¦é ç«¯TTSæœå‹™çš„ä¸åŒåƒæ•¸"""
    global remote_tts_service
    
    if not remote_tts_service:
        return jsonify({'error': 'é ç«¯TTSæœå‹™æœªåˆå§‹åŒ–'}), 500
    
    try:
        test_text = request.args.get('text', 'li2 ho2')
        
        # è§£æé¡å¤–åƒæ•¸
        additional_params = {}
        for key, value in request.args.items():
            if key != 'text':
                additional_params[key] = value
        
        print(f"ğŸ§ª æ¸¬è©¦é ç«¯TTS: '{test_text}'")
        if additional_params:
            print(f"ğŸ“ é¡å¤–åƒæ•¸: {additional_params}")
        
        # ä½¿ç”¨æ¸¬è©¦æ–¹æ³•
        audio_file = remote_tts_service.test_with_params(test_text, additional_params)
        
        result = {
            'test_text': test_text,
            'additional_params': additional_params,
            'audio_file': audio_file,
            'api_status': 'success' if audio_file else 'failed',
            'remote_url': f"{remote_tts_service.base_url}{remote_tts_service.endpoint}",
            'usage': {
                'basic': '/test_remote_tts?text=li2%20ho2',
                'with_params': '/test_remote_tts?text=li2%20ho2&version=1&model=default'
            }
        }
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e), 'api_status': 'failed'})

@app.route('/static/<path:filename>')
def serve_static(filename):
    """æä¾›éœæ…‹æª”æ¡ˆ"""
    return send_file(f'static/{filename}')

if __name__ == '__main__':
    print("ğŸ¯ å•Ÿå‹•å°èªèªéŸ³å°è©± Web æ‡‰ç”¨ç¨‹å¼")
    print("ğŸŒ æ•´åˆæ„å‚³ç§‘æŠ€ APIï¼ˆåŸºæ–¼ TauPhahJi-BangTsam è¦ç¯„ï¼‰")
    print("ğŸ”§ å·²ä¿®å¾©404éŒ¯èª¤éŸ³æª”æ•ç²å•é¡Œ")
    print("ğŸ“š API æ–‡æª”ä¾†æº: TauPhahJi-API-docs/APIå’Œçµ„ä»¶æ–‡æª”.md")
    print("=" * 50)
    
    # é¡¯ç¤ºAPIé…ç½®è³‡è¨Š
    print("API é…ç½®è³‡è¨Š:")
    for service_name, config in ITHUAN_API.items():
        print(f"   {service_name}: {config['ç¶²åŸŸ']}{config['ç«¯é»']} ({config['æ–¹æ³•']})")
    
    print(f"âš ï¸ ä½¿ç”¨é™åˆ¶: æ¯IPæ¯åˆ†é˜æœ€å¤š{API_LIMITS['æ¯åˆ†é˜ä¸‹è¼‰é™åˆ¶']}æ¬¡éŸ³æª”ä¸‹è¼‰")
    print("=" * 50)
    
    # åˆå§‹åŒ–å°èªæ¨¡å‹
    model_ready = init_taiwanese_model()
    
    # åˆå§‹åŒ–TTSæœå‹™å’Œæ ¼å¼è½‰æ›å™¨
    
    print("åˆå§‹åŒ–è‡ªè¨“ç·´é ç«¯TTSæœå‹™...")
    try:
        remote_tts_service = RemoteTtsService()
        print("é ç«¯TTSæœå‹™åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦é€£ç·š
        if remote_tts_service.test_connection():
            print("é ç«¯TTSæœå‹™é€£ç·šæ¸¬è©¦æˆåŠŸ")
        else:
            print("é ç«¯TTSæœå‹™é€£ç·šæ¸¬è©¦å¤±æ•—")
            
    except Exception as e:
        print(f"é ç«¯TTSæœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
        print("ç³»çµ±ç„¡æ³•æ­£å¸¸é‹ä½œ")
        remote_tts_service = None
    
    print("åˆå§‹åŒ–ç¾…é¦¬æ‹¼éŸ³æ ¼å¼è½‰æ›å™¨...")
    try:
        romanization_converter = RomanizationConverter()
        print("ç¾…é¦¬æ‹¼éŸ³è½‰æ›å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"ç¾…é¦¬æ‹¼éŸ³è½‰æ›å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
        print("å°‡ç›´æ¥ä½¿ç”¨åŸå§‹æ ¼å¼")
        romanization_converter = None
    
    if model_ready:
        print("ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
        print("å•Ÿå‹• Web æœå‹™...")
        print("è¨ªå• http://localhost:5000 é–‹å§‹ä½¿ç”¨")
        print("è¨ªå• http://localhost:5000/test_api æ¸¬è©¦ API")
        print("=" * 50)
        
        app.run(debug=True, host='0.0.0.0', port=5000)
    else:
        print("ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼Œç„¡æ³•å•Ÿå‹• Web æœå‹™")
        print("è«‹æª¢æŸ¥æ¨¡å‹å®‰è£å’Œç›¸é—œä¾è³´") 